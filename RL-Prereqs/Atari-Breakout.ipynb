{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ca21d1",
   "metadata": {},
   "source": [
    "# Import Dependencies\n",
    "\n",
    "Vec Frame Stack: In the main lecture, we didn't vectorize our environments. In Atari, we are training on 4 environments at the same time, so vectorizing them will make it a lot faster. <b> Question: Why are we using 4 different environments? <b>\n",
    "    \n",
    "evaluate_policy: tests out how a model is performing. Gets the average reward over a certain number of episodes\n",
    "    \n",
    "Check out Atari Environments: https://gym.openai.com/envs/#atari "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6bbc270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import VecFrameStack \n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6215f7c2",
   "metadata": {},
   "source": [
    "# Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e07bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying koolaid.bin from ./Roms/ROMS/Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/koolaid.bin\n",
      "copying alien.bin from ./Roms/ROMS/Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/alien.bin\n",
      "copying demon_attack.bin from ./Roms/ROMS/Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/demon_attack.bin\n",
      "copying crazy_climber.bin from ./Roms/ROMS/Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/crazy_climber.bin\n",
      "copying video_pinball.bin from ./Roms/ROMS/Pinball (AKA Video Pinball) (Zellers).bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/video_pinball.bin\n",
      "copying yars_revenge.bin from ./Roms/ROMS/Yars' Revenge (Time Freeze) (1982) (Atari, Howard Scott Warshaw - Sears) (CX2655 - 49-75167) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/yars_revenge.bin\n",
      "copying donkey_kong.bin from ./Roms/ROMS/Donkey Kong (1982) (Coleco - Woodside Design Associates - Imaginative Systems Software, Garry Kitchen) (2451) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/donkey_kong.bin\n",
      "copying carnival.bin from ./Roms/ROMS/Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/carnival.bin\n",
      "copying defender.bin from ./Roms/ROMS/Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/defender.bin\n",
      "copying gopher.bin from ./Roms/ROMS/Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/gopher.bin\n",
      "copying krull.bin from ./Roms/ROMS/Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/krull.bin\n",
      "copying pacman.bin from ./Roms/ROMS/Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/pacman.bin\n",
      "copying surround.bin from ./Roms/ROMS/Surround (32 in 1) (Bit Corporation) (R320).bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/surround.bin\n",
      "copying lost_luggage.bin from ./Roms/ROMS/Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/lost_luggage.bin\n",
      "copying pong.bin from ./Roms/ROMS/Video Olympics - Pong Sports (Paddle) (1977) (Atari, Joe Decuir - Sears) (CX2621 - 99806, 6-99806, 49-75104) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/pong.bin\n",
      "copying keystone_kapers.bin from ./Roms/ROMS/Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/keystone_kapers.bin\n",
      "copying kung_fu_master.bin from ./Roms/ROMS/Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/kung_fu_master.bin\n",
      "copying trondead.bin from ./Roms/ROMS/TRON - Deadly Discs (TRON Joystick) (1983) (M Network - INTV - APh Technological Consulting, Jeff Ronne, Brett Stutz) (MT5662) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/trondead.bin\n",
      "copying air_raid.bin from ./Roms/ROMS/Air Raid (Men-A-Vision) (PAL) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/air_raid.bin\n",
      "copying name_this_game.bin from ./Roms/ROMS/Name This Game (Guardians of Treasure) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/name_this_game.bin\n",
      "copying king_kong.bin from ./Roms/ROMS/King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/king_kong.bin\n",
      "copying qbert.bin from ./Roms/ROMS/Q-bert (1983) (Parker Brothers - Western Technologies, Dave Hampton, Tom Sloper) (PB5360) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/qbert.bin\n",
      "copying robotank.bin from ./Roms/ROMS/Robot Tank (Robotank) (1983) (Activision, Alan Miller) (AZ-028, AG-028-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/robotank.bin\n",
      "copying skiing.bin from ./Roms/ROMS/Skiing - Le Ski (1980) (Activision, Bob Whitehead) (AG-005, CAG-005, AG-005-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/skiing.bin\n",
      "copying hero.bin from ./Roms/ROMS/H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/hero.bin\n",
      "copying star_gunner.bin from ./Roms/ROMS/Stargunner (1983) (Telesys, Alex Leavens) (1005) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/star_gunner.bin\n",
      "copying tutankham.bin from ./Roms/ROMS/Tutankham (1983) (Parker Brothers, Dave Engman, Dawn Stockbridge) (PB5340) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/tutankham.bin\n",
      "copying gravitar.bin from ./Roms/ROMS/Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/gravitar.bin\n",
      "copying jamesbond.bin from ./Roms/ROMS/James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Louis Marbel) (PB5110) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/jamesbond.bin\n",
      "copying montezuma_revenge.bin from ./Roms/ROMS/Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
      "copying venture.bin from ./Roms/ROMS/Venture (1982) (Coleco, Joseph Biel) (2457) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/venture.bin\n",
      "copying pitfall.bin from ./Roms/ROMS/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/pitfall.bin\n",
      "copying laser_gates.bin from ./Roms/ROMS/Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/laser_gates.bin\n",
      "copying tennis.bin from ./Roms/ROMS/Tennis - Le Tennis (1981) (Activision, Alan Miller) (AG-007, CAG-007) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/tennis.bin\n",
      "copying space_invaders.bin from ./Roms/ROMS/Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/space_invaders.bin\n",
      "copying mr_do.bin from ./Roms/ROMS/Mr. Do! (1983) (CBS Electronics, Ed English) (4L4478) (PAL).bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/mr_do.bin\n",
      "copying up_n_down.bin from ./Roms/ROMS/Up 'n Down (1984) (SEGA - Beck-Tech, Steve Beck, Phat Ho) (009-01) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/up_n_down.bin\n",
      "copying kaboom.bin from ./Roms/ROMS/Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, AG-010-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/kaboom.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying galaxian.bin from ./Roms/ROMS/Galaxian (1983) (Atari - GCC, Mark Ackerman, Tom Calderwood, Glenn Parker) (CX2684) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/galaxian.bin\n",
      "copying riverraid.bin from ./Roms/ROMS/River Raid (1982) (Activision, Carol Shaw) (AX-020, AX-020-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/riverraid.bin\n",
      "copying enduro.bin from ./Roms/ROMS/Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/enduro.bin\n",
      "copying amidar.bin from ./Roms/ROMS/Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/amidar.bin\n",
      "copying bowling.bin from ./Roms/ROMS/Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/bowling.bin\n",
      "copying atlantis.bin from ./Roms/ROMS/Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/atlantis.bin\n",
      "copying breakout.bin from ./Roms/ROMS/Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/breakout.bin\n",
      "copying phoenix.bin from ./Roms/ROMS/Phoenix (1983) (Atari - GCC, Mike Feinstein, John Mracek) (CX2673) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/phoenix.bin\n",
      "copying asterix.bin from ./Roms/ROMS/Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/asterix.bin\n",
      "copying frostbite.bin from ./Roms/ROMS/Frostbite (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/frostbite.bin\n",
      "copying seaquest.bin from ./Roms/ROMS/Seaquest (1983) (Activision, Steve Cartwright) (AX-022) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/seaquest.bin\n",
      "copying road_runner.bin from patched version of ./Roms/ROMS/Road Runner (1989) (Atari - Bobco, Robert C. Polaro) (CX2663) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/road_runner.bin\n",
      "copying berzerk.bin from ./Roms/ROMS/Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/berzerk.bin\n",
      "copying ms_pacman.bin from ./Roms/ROMS/Ms. Pac-Man (1983) (Atari - GCC, Mark Ackerman, Glenn Parker) (CX2675) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/ms_pacman.bin\n",
      "copying centipede.bin from ./Roms/ROMS/Centipede (1983) (Atari - GCC) (CX2676) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/centipede.bin\n",
      "copying elevator_action.bin from ./Roms/ROMS/Elevator Action (1983) (Atari, Dan Hitchens) (CX26126) (Prototype) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/elevator_action.bin\n",
      "copying double_dunk.bin from ./Roms/ROMS/Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/double_dunk.bin\n",
      "copying assault.bin from ./Roms/ROMS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/assault.bin\n",
      "copying ice_hockey.bin from ./Roms/ROMS/Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/ice_hockey.bin\n",
      "copying zaxxon.bin from ./Roms/ROMS/Zaxxon (1983) (Coleco) (2454) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/zaxxon.bin\n",
      "copying beam_rider.bin from ./Roms/ROMS/Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/beam_rider.bin\n",
      "copying sir_lancelot.bin from ./Roms/ROMS/Sir Lancelot (1983) (Xonox - K-Tel Software - Product Guild, Anthony R. Henderson) (99006, 6220) (PAL).bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/sir_lancelot.bin\n",
      "copying wizard_of_wor.bin from ./Roms/ROMS/Wizard of Wor (1982) (CBS Electronics - Roklan, Joe Hellesen, Joe Wagner) (M8774, M8794) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/wizard_of_wor.bin\n",
      "copying bank_heist.bin from ./Roms/ROMS/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/bank_heist.bin\n",
      "copying private_eye.bin from ./Roms/ROMS/Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/private_eye.bin\n",
      "copying battle_zone.bin from ./Roms/ROMS/Battlezone (1983) (Atari - GCC, Mike Feinstein, Brad Rice) (CX2681) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/battle_zone.bin\n",
      "copying journey_escape.bin from ./Roms/ROMS/Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/journey_escape.bin\n",
      "copying kangaroo.bin from ./Roms/ROMS/Kangaroo (1983) (Atari - GCC, Kevin Osborn) (CX2689) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/kangaroo.bin\n",
      "copying boxing.bin from ./Roms/ROMS/Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/boxing.bin\n",
      "copying fishing_derby.bin from ./Roms/ROMS/Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/fishing_derby.bin\n",
      "copying freeway.bin from ./Roms/ROMS/Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/freeway.bin\n",
      "copying pooyan.bin from ./Roms/ROMS/Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/pooyan.bin\n",
      "copying asteroids.bin from ./Roms/ROMS/Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/asteroids.bin\n",
      "copying frogger.bin from ./Roms/ROMS/Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/frogger.bin\n",
      "copying chopper_command.bin from ./Roms/ROMS/Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/chopper_command.bin\n",
      "copying time_pilot.bin from ./Roms/ROMS/Time Pilot (1983) (Coleco - Woodside Design Associates, Harley H. Puthuff Jr.) (2663) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/time_pilot.bin\n",
      "copying adventure.bin from ./Roms/ROMS/Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/adventure.bin\n",
      "copying solaris.bin from ./Roms/ROMS/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986) (Atari, Douglas Neubauer, Mimi Nyden) (CX26136) ~.bin to /Users/shrutisharma/anaconda3/lib/python3.6/site-packages/atari_py/atari_roms/solaris.bin\n"
     ]
    }
   ],
   "source": [
    "!python -m atari_py.import_roms ./Roms/ROMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6191a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'Breakout-v0'\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b93a2420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset() # remember that this gets our observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169cb57",
   "metadata": {},
   "source": [
    "<b>Pro Tip: Sometimes to find what action and observations mean, you're going to have to look at the source code on GitHub if there is no clear documentation<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fb11c4",
   "metadata": {},
   "source": [
    "Action space is Discrete and there are 4 different actions to take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "533a33da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c077171f",
   "metadata": {},
   "source": [
    "Observation Space ranges from 0 - 255 and has shape (210, 160, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50a64bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([[[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]\n",
       "\n",
       " [[0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  ...\n",
       "  [0 0 0]\n",
       "  [0 0 0]\n",
       "  [0 0 0]]], [[[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]\n",
       "\n",
       " [[255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  ...\n",
       "  [255 255 255]\n",
       "  [255 255 255]\n",
       "  [255 255 255]]], (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf3403ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:0.0\n",
      "Episode:2 Score:4.0\n",
      "Episode:3 Score:2.0\n",
      "Episode:4 Score:4.0\n",
      "Episode:5 Score:2.0\n"
     ]
    }
   ],
   "source": [
    "# test out environments, seeing how the agent can interact with it. \n",
    "episodes = 5 # test 5 times\n",
    "for episode in range(1, episodes + 1): # loop through each episode\n",
    "    obs = env.reset()  # reset environment every time theres a new episode, get an initial set of observations\n",
    "    # these observations are passed to the reinforcement agent to determine best action to maximize reward, but we aren't doing that right now\n",
    "    done = False # episode is not done\n",
    "    score = 0 \n",
    "    \n",
    "    #actions will move bar to the left and to the right\n",
    "    while not done: \n",
    "        env.render() # visual representation of env. \n",
    "        action = env.action_space.sample() # generate a random action, NOT an action informed by observations\n",
    "        obs, reward, done, info = env.step(action) # pass through random action -a forward pass, or in this case, \n",
    "        #supply an action to the environment, gets an observation back.\n",
    "        # get back the next set of observations, the reward for taking the inputted action, (positive for increase, negative for decrease (includes 0). \n",
    "        #whether episode is done. If done, stop. )\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7af110",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be0e6f",
   "metadata": {},
   "source": [
    "# Vectorize Environment and Train Model\n",
    "\n",
    "<b> make_atari_env </b>: a method from stable baselines that helps create wrapped Atari environments\n",
    "    \n",
    "<b> VecFrameStack</b>: stacks the environments together\n",
    "    \n",
    "<b> Question: What is an environment wrapper? </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79f2efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env('Breakout-v0', n_envs = 4, seed = 0)\n",
    "env = VecFrameStack(env, n_stack = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd7d448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7712b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7349bf",
   "metadata": {},
   "source": [
    "<b>IMPORTANT:</b> Before, we were using an Mlp policy (multilayer perceptron - is that just a multi layer neural network> - for Cartpole, which is a good policy for tabular data, but Breakout-v0 uses image observations, so it's better to use the Cnn policy (Convoluted Neural Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfd7a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "model = A2C('CnnPolicy', env, verbose = 1, tensorboard_log = log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30e8e707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 272      |\n",
      "|    ep_rew_mean        | 1.42     |\n",
      "| time/                 |          |\n",
      "|    fps                | 87       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.559    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.0754  |\n",
      "|    value_loss         | 0.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 283      |\n",
      "|    ep_rew_mean        | 1.6      |\n",
      "| time/                 |          |\n",
      "|    fps                | 93       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 0.355    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.313    |\n",
      "|    value_loss         | 0.279    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 288      |\n",
      "|    ep_rew_mean        | 1.73     |\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 0.923    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.0146   |\n",
      "|    value_loss         | 0.0176   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 301      |\n",
      "|    ep_rew_mean        | 1.97     |\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | 0.946    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.233   |\n",
      "|    value_loss         | 0.0751   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 314      |\n",
      "|    ep_rew_mean        | 2.23     |\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | 0.981    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.00855 |\n",
      "|    value_loss         | 0.014    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 323      |\n",
      "|    ep_rew_mean        | 2.37     |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0.902    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.141   |\n",
      "|    value_loss         | 0.0318   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 322      |\n",
      "|    ep_rew_mean        | 2.37     |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | 0.901    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.039    |\n",
      "|    value_loss         | 0.0709   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 311      |\n",
      "|    ep_rew_mean        | 2.24     |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0.868    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.0436   |\n",
      "|    value_loss         | 0.0162   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 317      |\n",
      "|    ep_rew_mean        | 2.33     |\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.23    |\n",
      "|    explained_variance | 0.979    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.0084   |\n",
      "|    value_loss         | 0.00731  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 318      |\n",
      "|    ep_rew_mean        | 2.37     |\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | 0.941    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.0177  |\n",
      "|    value_loss         | 0.0194   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 323      |\n",
      "|    ep_rew_mean        | 2.42     |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0.805    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.153    |\n",
      "|    value_loss         | 0.0991   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 324      |\n",
      "|    ep_rew_mean        | 2.46     |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | -13.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.0256  |\n",
      "|    value_loss         | 0.00521  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 327      |\n",
      "|    ep_rew_mean        | 2.51     |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.71     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.281    |\n",
      "|    value_loss         | 0.2      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 327      |\n",
      "|    ep_rew_mean        | 2.48     |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.151    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.289    |\n",
      "|    value_loss         | 0.454    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 331      |\n",
      "|    ep_rew_mean        | 2.56     |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 0.644    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.126    |\n",
      "|    value_loss         | 0.0808   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 346      |\n",
      "|    ep_rew_mean        | 2.92     |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | 0.857    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.0821  |\n",
      "|    value_loss         | 0.0598   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 358      |\n",
      "|    ep_rew_mean        | 3.22     |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 311      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.645   |\n",
      "|    explained_variance | 0.851    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.271   |\n",
      "|    value_loss         | 0.241    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 375      |\n",
      "|    ep_rew_mean        | 3.73     |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.958   |\n",
      "|    explained_variance | 0.648    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.0933   |\n",
      "|    value_loss         | 0.187    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 396      |\n",
      "|    ep_rew_mean        | 4.18     |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 344      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.872   |\n",
      "|    explained_variance | 0.512    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.0748   |\n",
      "|    value_loss         | 0.0371   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 405      |\n",
      "|    ep_rew_mean        | 4.35     |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.913   |\n",
      "|    explained_variance | 0.906    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.279    |\n",
      "|    value_loss         | 0.126    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 417      |\n",
      "|    ep_rew_mean        | 4.62     |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 376      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.406   |\n",
      "|    explained_variance | 0.304    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.00744  |\n",
      "|    value_loss         | 0.0879   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 424      |\n",
      "|    ep_rew_mean        | 4.74     |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 393      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.968   |\n",
      "|    explained_variance | 0.783    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.046   |\n",
      "|    value_loss         | 0.0666   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 445      |\n",
      "|    ep_rew_mean        | 5.05     |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 409      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.545   |\n",
      "|    explained_variance | 0.753    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.127    |\n",
      "|    value_loss         | 0.198    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 445      |\n",
      "|    ep_rew_mean        | 5.09     |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 425      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.93    |\n",
      "|    explained_variance | 0.751    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.0148  |\n",
      "|    value_loss         | 0.0919   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 449       |\n",
      "|    ep_rew_mean        | 5.21      |\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 441       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.81     |\n",
      "|    explained_variance | 0.946     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -0.000498 |\n",
      "|    value_loss         | 0.0657    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 457      |\n",
      "|    ep_rew_mean        | 5.4      |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 458      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.996   |\n",
      "|    explained_variance | 0.921    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.178   |\n",
      "|    value_loss         | 0.082    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 454      |\n",
      "|    ep_rew_mean        | 5.4      |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 474      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.552   |\n",
      "|    explained_variance | 0.909    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.234    |\n",
      "|    value_loss         | 0.177    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 436      |\n",
      "|    ep_rew_mean        | 5.07     |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 490      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | 0.972    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.0708  |\n",
      "|    value_loss         | 0.0227   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 440      |\n",
      "|    ep_rew_mean        | 5.14     |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 506      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.756   |\n",
      "|    explained_variance | 0.901    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.0321  |\n",
      "|    value_loss         | 0.0375   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 442      |\n",
      "|    ep_rew_mean        | 5.12     |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 522      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.973   |\n",
      "|    explained_variance | 0.883    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.195   |\n",
      "|    value_loss         | 0.216    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 439      |\n",
      "|    ep_rew_mean        | 5.05     |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 539      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.432   |\n",
      "|    explained_variance | 0.862    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.162    |\n",
      "|    value_loss         | 0.216    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 454      |\n",
      "|    ep_rew_mean        | 5.31     |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 555      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.864   |\n",
      "|    explained_variance | 0.449    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.177    |\n",
      "|    value_loss         | 0.293    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 462      |\n",
      "|    ep_rew_mean        | 5.43     |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 572      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.949   |\n",
      "|    explained_variance | 0.73     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    value_loss         | 0.136    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 461      |\n",
      "|    ep_rew_mean        | 5.43     |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 588      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.915   |\n",
      "|    explained_variance | 0.685    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.0609   |\n",
      "|    value_loss         | 0.0191   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 469      |\n",
      "|    ep_rew_mean        | 5.62     |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 604      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.723   |\n",
      "|    explained_variance | 0.982    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.0394  |\n",
      "|    value_loss         | 0.0163   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 481      |\n",
      "|    ep_rew_mean        | 5.88     |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 621      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.535   |\n",
      "|    explained_variance | 0.886    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.235    |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 485      |\n",
      "|    ep_rew_mean        | 5.91     |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 637      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 0.838    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.079   |\n",
      "|    value_loss         | 0.0602   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 492      |\n",
      "|    ep_rew_mean        | 6.04     |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 653      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.911   |\n",
      "|    explained_variance | 0.764    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.105    |\n",
      "|    value_loss         | 0.176    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 501      |\n",
      "|    ep_rew_mean        | 6.23     |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 669      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.577   |\n",
      "|    explained_variance | 0.835    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.0357  |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 510      |\n",
      "|    ep_rew_mean        | 6.34     |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 685      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.666   |\n",
      "|    explained_variance | 0.878    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.204    |\n",
      "|    value_loss         | 0.192    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 505      |\n",
      "|    ep_rew_mean        | 6.22     |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 703      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.673   |\n",
      "|    explained_variance | 0.898    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.00555  |\n",
      "|    value_loss         | 0.0261   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 494      |\n",
      "|    ep_rew_mean        | 6.1      |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 718      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.653   |\n",
      "|    explained_variance | 0.666    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.17    |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 499      |\n",
      "|    ep_rew_mean        | 6.18     |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 733      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.4     |\n",
      "|    explained_variance | 0.764    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.122    |\n",
      "|    value_loss         | 0.0818   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 490      |\n",
      "|    ep_rew_mean        | 6.1      |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 747      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.793   |\n",
      "|    explained_variance | 0.823    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.0359  |\n",
      "|    value_loss         | 0.0502   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 489      |\n",
      "|    ep_rew_mean        | 6.13     |\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 762      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.65    |\n",
      "|    explained_variance | 0.329    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.241   |\n",
      "|    value_loss         | 0.0907   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 496      |\n",
      "|    ep_rew_mean        | 6.37     |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 780      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.456   |\n",
      "|    explained_variance | 0.304    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.0877   |\n",
      "|    value_loss         | 0.077    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 517      |\n",
      "|    ep_rew_mean        | 6.76     |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 799      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.491   |\n",
      "|    explained_variance | 0.228    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.214   |\n",
      "|    value_loss         | 0.234    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 531      |\n",
      "|    ep_rew_mean        | 6.95     |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 816      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.261   |\n",
      "|    explained_variance | 0.828    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.0174  |\n",
      "|    value_loss         | 0.306    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 531      |\n",
      "|    ep_rew_mean        | 6.99     |\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 831      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.157   |\n",
      "|    explained_variance | 0.907    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.0307  |\n",
      "|    value_loss         | 0.0459   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 532      |\n",
      "|    ep_rew_mean        | 6.93     |\n",
      "| time/                 |          |\n",
      "|    fps                | 118      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 847      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.408   |\n",
      "|    explained_variance | 0.807    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.132    |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7f83561cc198>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps = 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b487a753",
   "metadata": {},
   "source": [
    "# Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "425a4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_path = os.path.join(\"Training\", \"Saved Models\", \"A2C_Breakout_Model\")\n",
    "model.save(a2c_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcea9e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = A2C.load(a2c_path, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eed1796",
   "metadata": {},
   "source": [
    "# Evaluate and Test Model\n",
    "<b>IMPORTANT: </b>So, the evaluate_policy() method takes in environments that are non_vectorized, or only one environment at a time. Recall that we trained our model on a vectorized environment (4 different environments). There's actually a way to get around this. We can remake the environment as a single environments, but then stack it as 4 so that we can technically still pass through all 4 environments. To be honest, I don't really get it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bf00a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50622b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env('Breakout-v0', n_envs = 1, seed = 0)\n",
    "env = VecFrameStack(env, n_stack = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f853f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.7, 2.8653097563788807)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes = 10, render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530b4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
